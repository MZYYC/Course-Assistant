#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºLangChainçš„å¤šæ ¼å¼æ–‡æ¡£åŠ è½½å™¨
æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼çš„åŠ è½½ï¼ŒåŒ…å«æŒä¹…åŒ–å’Œè¿›åº¦è·Ÿè¸ªåŠŸèƒ½
"""

import sys
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import json
import os
import time
import mimetypes
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from langchain_core.documents import Document
from langchain_community.document_loaders import (
    PyPDFLoader,
    TextLoader,
    UnstructuredMarkdownLoader,
    UnstructuredWordDocumentLoader,
    UnstructuredPowerPointLoader,
    UnstructuredExcelLoader,
    CSVLoader,
    UnstructuredHTMLLoader,
    UnstructuredXMLLoader
)
from config import Config


class LangChainDocumentLoader:
    """åŸºäºLangChainçš„å¤šæ ¼å¼æ–‡æ¡£åŠ è½½å™¨"""
    
    def __init__(self, documents_path: str, persistence_manager=None):
        self.documents_path = Path(documents_path)
        self.persistence_manager = persistence_manager
        self.supported_extensions = {
            # æ–‡æ¡£æ ¼å¼
            '.pdf': self._load_pdf,
            '.doc': self._load_docx,
            '.docx': self._load_docx,
            '.ppt': self._load_pptx,
            '.pptx': self._load_pptx,
            
            # æ–‡æœ¬æ ¼å¼
            '.txt': self._load_text,
            '.md': self._load_markdown,
            '.markdown': self._load_markdown,
            '.rst': self._load_text,
            
            # ç»“æ„åŒ–æ•°æ®
            '.json': self._load_json,
            '.jsonl': self._load_jsonl,
            '.csv': self._load_csv,
            '.xlsx': self._load_excel,
            '.xls': self._load_excel,
            
            # ç½‘é¡µå’Œæ ‡è®°è¯­è¨€
            '.html': self._load_html,
            '.htm': self._load_html,
            '.xml': self._load_xml,
            
            # ä»£ç æ–‡ä»¶
            '.py': self._load_text,
            '.js': self._load_text,
            '.ts': self._load_text,
            '.java': self._load_text,
            '.cpp': self._load_text,
            '.c': self._load_text,
            '.cs': self._load_text,
            '.go': self._load_text,
            '.rs': self._load_text,
            '.php': self._load_text,
            '.rb': self._load_text,
            '.sh': self._load_text,
            '.sql': self._load_text,
            '.yml': self._load_text,
            '.yaml': self._load_text,
            '.toml': self._load_text,
            '.ini': self._load_text,
            '.cfg': self._load_text,
            '.conf': self._load_text,
            '.log': self._load_text
        }
        
        # åŠ è½½ç»Ÿè®¡
        self.load_stats = {
            'total_files': 0,
            'successful_loads': 0,
            'failed_loads': 0,
            'total_documents': 0,
            'by_type': {},
            'errors': []
        }
        
        print(f"æ–‡æ¡£åŠ è½½å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ”¯æŒ {len(self.supported_extensions)} ç§æ–‡ä»¶æ ¼å¼")
    
    def load_documents(self) -> List[Document]:
        """é€’å½’åŠ è½½æ‰€æœ‰æ”¯æŒçš„æ–‡æ¡£"""
        documents = []
        start_time = time.time()
        
        # é‡ç½®ç»Ÿè®¡
        self.load_stats = {
            'total_files': 0,
            'successful_loads': 0,
            'failed_loads': 0,
            'total_documents': 0,
            'by_type': {},
            'errors': [],
            'start_time': datetime.now().isoformat(),
            'processing_time': 0
        }
        
        if not self.documents_path.exists():
            print(f"æ–‡æ¡£è·¯å¾„ä¸å­˜åœ¨: {self.documents_path}")
            return documents
        
        print(f"å¼€å§‹åŠ è½½æ–‡æ¡£ï¼Œè·¯å¾„: {self.documents_path}")
        
        # æ”¶é›†æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶
        all_files = []
        for file_path in self.documents_path.rglob('*'):
            if file_path.is_file():
                file_extension = file_path.suffix.lower()
                if file_extension in self.supported_extensions:
                    all_files.append(file_path)
        
        self.load_stats['total_files'] = len(all_files)
        print(f"æ‰¾åˆ° {len(all_files)} ä¸ªæ”¯æŒçš„æ–‡ä»¶")
        
        # é€’å½’éå†æ‰€æœ‰æ–‡ä»¶
        for i, file_path in enumerate(all_files):
            file_extension = file_path.suffix.lower()
            file_type = self._get_file_type(file_extension)
            
            try:
                print(f"æ­£åœ¨åŠ è½½ [{i+1}/{len(all_files)}]: {file_path.name}")
                
                loader_func = self.supported_extensions[file_extension]
                docs = loader_func(file_path)
                
                if docs:
                    documents.extend(docs)
                    self.load_stats['successful_loads'] += 1
                    self.load_stats['total_documents'] += len(docs)
                    
                    # æŒ‰ç±»å‹ç»Ÿè®¡
                    if file_type not in self.load_stats['by_type']:
                        self.load_stats['by_type'][file_type] = {'files': 0, 'documents': 0}
                    self.load_stats['by_type'][file_type]['files'] += 1
                    self.load_stats['by_type'][file_type]['documents'] += len(docs)
                    
                    print(f"æˆåŠŸåŠ è½½: {file_path.name}, è·å¾— {len(docs)} ä¸ªæ–‡æ¡£")
                else:
                    self.load_stats['failed_loads'] += 1
                    error_msg = f"æ–‡ä»¶ä¸ºç©ºæˆ–æ— å†…å®¹: {file_path}"
                    self.load_stats['errors'].append(error_msg)
                    print(f"âš ï¸ {error_msg}")
                    
            except Exception as e:
                self.load_stats['failed_loads'] += 1
                error_msg = f"åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}"
                self.load_stats['errors'].append(error_msg)
                print(f"âŒ {error_msg}")
                continue
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = time.time() - start_time
        self.load_stats['processing_time'] = processing_time
        self.load_stats['end_time'] = datetime.now().isoformat()
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        self._print_load_statistics()
        
        # è®°å½•æ–‡æ¡£å¤„ç†å†å²åˆ°æŒä¹…åŒ–ç³»ç»Ÿ
        if self.persistence_manager and documents:
            try:
                self.persistence_manager.save_document_history(
                    file_path=str(self.documents_path),
                    file_name=f"multi-format-{self.load_stats['successful_loads']}-files",
                    file_size=sum(len(doc.page_content.encode('utf-8')) for doc in documents),
                    processing_time=processing_time,
                    success=True,
                    chunk_count=len(documents),
                    strategy="multi-format-loading"
                )
            except Exception as e:
                print(f"âš ï¸ æŒä¹…åŒ–è®°å½•å¤±è´¥: {e}")
        
        return documents
    
    def _get_file_type(self, extension: str) -> str:
        """æ ¹æ®æ‰©å±•åè·å–æ–‡ä»¶ç±»å‹"""
        type_mapping = {
            '.pdf': 'PDF',
            '.doc': 'Word', '.docx': 'Word',
            '.ppt': 'PowerPoint', '.pptx': 'PowerPoint',
            '.txt': 'Text', '.md': 'Markdown', '.markdown': 'Markdown', '.rst': 'Text',
            '.json': 'JSON', '.jsonl': 'JSONL',
            '.csv': 'CSV', '.xlsx': 'Excel', '.xls': 'Excel',
            '.html': 'HTML', '.htm': 'HTML', '.xml': 'XML',
            '.py': 'Code', '.js': 'Code', '.ts': 'Code', '.java': 'Code',
            '.cpp': 'Code', '.c': 'Code', '.cs': 'Code', '.go': 'Code',
            '.rs': 'Code', '.php': 'Code', '.rb': 'Code', '.sh': 'Code',
            '.sql': 'Code', '.yml': 'Config', '.yaml': 'Config',
            '.toml': 'Config', '.ini': 'Config', '.cfg': 'Config',
            '.conf': 'Config', '.log': 'Log'
        }
        return type_mapping.get(extension, 'Unknown')
    
    def _print_load_statistics(self):
        """æ‰“å°åŠ è½½ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.load_stats
        print(f"\nğŸ“Š æ–‡æ¡£åŠ è½½ç»Ÿè®¡:")
        print(f"   æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"   æˆåŠŸåŠ è½½: {stats['successful_loads']}")
        print(f"   åŠ è½½å¤±è´¥: {stats['failed_loads']}")
        print(f"   æ€»æ–‡æ¡£æ•°: {stats['total_documents']}")
        print(f"   å¤„ç†æ—¶é—´: {stats['processing_time']:.2f}s")
        
        if stats['by_type']:
            print(f"   æŒ‰ç±»å‹ç»Ÿè®¡:")
            for file_type, counts in stats['by_type'].items():
                print(f"     {file_type}: {counts['files']} æ–‡ä»¶, {counts['documents']} æ–‡æ¡£")
        
        if stats['errors']:
            print(f"   é”™è¯¯æ•°: {len(stats['errors'])}")
            if len(stats['errors']) <= 5:
                for error in stats['errors']:
                    print(f"     - {error}")
            else:
                for error in stats['errors'][:3]:
                    print(f"     - {error}")
                print(f"     ... è¿˜æœ‰ {len(stats['errors']) - 3} ä¸ªé”™è¯¯")
        
        print(f"æ–‡æ¡£åŠ è½½å®Œæˆï¼Œå…±åŠ è½½ {stats['total_documents']} ä¸ªæ–‡æ¡£\n")
    
    def _load_pdf(self, file_path: Path) -> List[Document]:
        """åŠ è½½PDFæ–‡æ¡£"""
        try:
            loader = PyPDFLoader(str(file_path))
            documents = loader.load()
            
            # æ·»åŠ å…ƒæ•°æ®
            for doc in documents:
                doc.metadata.update({
                    'source': str(file_path),
                    'file_type': 'pdf',
                    'file_name': file_path.name
                })
            
            return documents
        except Exception as e:
            print(f"åŠ è½½PDFæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return []
    
    def _load_markdown(self, file_path: Path) -> List[Document]:
        """åŠ è½½Markdownæ–‡æ¡£"""
        try:
            loader = UnstructuredMarkdownLoader(str(file_path))
            documents = loader.load()
            
            # æ·»åŠ å…ƒæ•°æ®
            for doc in documents:
                doc.metadata.update({
                    'source': str(file_path),
                    'file_type': 'markdown',
                    'file_name': file_path.name
                })
            
            return documents
        except Exception as e:
            print(f"åŠ è½½Markdownæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return []
    
    def _load_docx(self, file_path: Path) -> List[Document]:
        """åŠ è½½Wordæ–‡æ¡£"""
        try:
            loader = UnstructuredWordDocumentLoader(str(file_path))
            documents = loader.load()
            
            # æ·»åŠ å…ƒæ•°æ®
            for doc in documents:
                doc.metadata.update({
                    'source': str(file_path),
                    'file_type': 'docx',
                    'file_name': file_path.name
                })
            
            return documents
        except Exception as e:
            print(f"åŠ è½½Wordæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return []
    
    def _load_pptx(self, file_path: Path) -> List[Document]:
        """åŠ è½½PowerPointæ–‡æ¡£"""
        try:
            loader = UnstructuredPowerPointLoader(str(file_path))
            documents = loader.load()
            
            # æ·»åŠ å…ƒæ•°æ®
            for doc in documents:
                doc.metadata.update({
                    'source': str(file_path),
                    'file_type': 'pptx',
                    'file_name': file_path.name
                })
            
            return documents
        except Exception as e:
            print(f"åŠ è½½PowerPointæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return []
    
    def _load_text(self, file_path: Path) -> List[Document]:
        """åŠ è½½æ–‡æœ¬æ–‡æ¡£"""
        try:
            loader = TextLoader(str(file_path), encoding='utf-8')
            documents = loader.load()
            
            # æ·»åŠ å…ƒæ•°æ®
            for doc in documents:
                doc.metadata.update({
                    'source': str(file_path),
                    'file_type': 'txt',
                    'file_name': file_path.name
                })
            
            return documents
        except UnicodeDecodeError:
            # å°è¯•å…¶ä»–ç¼–ç 
            for encoding in ['gbk', 'gb2312', 'latin-1']:
                try:
                    loader = TextLoader(str(file_path), encoding=encoding)
                    documents = loader.load()
                    for doc in documents:
                        doc.metadata.update({
                            'source': str(file_path),
                            'file_type': 'txt',
                            'file_name': file_path.name,
                            'encoding': encoding
                        })
                    return documents
                except:
                    continue
            print(f"åŠ è½½æ–‡æœ¬æ–‡ä»¶å¤±è´¥ {file_path}: æ— æ³•è¯†åˆ«ç¼–ç ")
            return []
        except Exception as e:
            print(f"åŠ è½½æ–‡æœ¬æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return []
    
    def _load_jsonl(self, file_path: Path) -> List[Document]:
        """åŠ è½½JSONLæ–‡ä»¶ (æ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡)"""
        documents = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if line.strip():
                        try:
                            data = json.loads(line)
                            # æå–æ–‡æœ¬å†…å®¹
                            text = ""
                            if isinstance(data, dict):
                                # å°è¯•å¸¸è§çš„æ–‡æœ¬å­—æ®µ
                                for key in ['text', 'content', 'body', 'message', 'description']:
                                    if key in data and data[key]:
                                        text = str(data[key])
                                        break
                                if not text:
                                    text = json.dumps(data, ensure_ascii=False)
                            else:
                                text = str(data)
                            
                            if text:
                                doc = Document(
                                    page_content=text,
                                    metadata={
                                        'source': str(file_path),
                                        'line_number': i + 1,
                                        'file_type': 'jsonl',
                                        'file_name': file_path.name
                                    }
                                )
                                documents.append(doc)
                        except json.JSONDecodeError:
                            continue
            return documents
        except Exception as e:
            print(f"JSONLæ–‡ä»¶åŠ è½½å¤±è´¥ {file_path}: {e}")
            return []
    
    def _load_csv(self, file_path: Path) -> List[Document]:
        """åŠ è½½CSVæ–‡ä»¶"""
        try:
            loader = CSVLoader(file_path=str(file_path))
            documents = loader.load()
            
            # æ·»åŠ å…ƒæ•°æ®
            for doc in documents:
                doc.metadata.update({
                    'source': str(file_path),
                    'file_type': 'csv',
                    'file_name': file_path.name
                })
            
            return documents
        except Exception as e:
            print(f"CSVåŠ è½½å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨è§£æ: {e}")
            # æ‰‹åŠ¨è§£æCSV
            documents = []
            try:
                import csv
                with open(file_path, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for i, row in enumerate(reader):
                        if row:
                            # å°†æ‰€æœ‰å­—æ®µç»„åˆæˆæ–‡æœ¬
                            text_parts = []
                            for key, value in row.items():
                                if value:
                                    text_parts.append(f"{key}: {value}")
                            
                            if text_parts:
                                text = "\n".join(text_parts)
                                doc = Document(
                                    page_content=text,
                                    metadata={
                                        'source': str(file_path),
                                        'row_number': i + 1,
                                        'file_type': 'csv',
                                        'file_name': file_path.name
                                    }
                                )
                                documents.append(doc)
                return documents
            except Exception:
                return []
    
    def _load_excel(self, file_path: Path) -> List[Document]:
        """åŠ è½½Excelæ–‡ä»¶"""
        try:
            from langchain_community.document_loaders import UnstructuredExcelLoader
            loader = UnstructuredExcelLoader(str(file_path), mode="elements")
            documents = loader.load()
            
            # æ·»åŠ å…ƒæ•°æ®
            for doc in documents:
                doc.metadata.update({
                    'source': str(file_path),
                    'file_type': 'excel',
                    'file_name': file_path.name
                })
            
            return documents
        except ImportError:
            print("æœªå®‰è£…unstructuredåº“ï¼Œå°è¯•ä½¿ç”¨pandasè§£æExcel")
            # ä½¿ç”¨pandasè§£æ
            try:
                import pandas as pd
                documents = []
                
                # è¯»å–æ‰€æœ‰å·¥ä½œè¡¨
                excel_file = pd.ExcelFile(file_path)
                for sheet_name in excel_file.sheet_names:
                    df = pd.read_excel(file_path, sheet_name=sheet_name)
                    
                    # å°†æ¯è¡Œè½¬æ¢ä¸ºæ–‡æ¡£
                    for row_idx, (index, row) in enumerate(df.iterrows()):
                        text_parts = []
                        for col, value in row.items():
                            if pd.notna(value):
                                text_parts.append(f"{col}: {value}")
                        
                        if text_parts:
                            text = "\n".join(text_parts)
                            doc = Document(
                                page_content=text,
                                metadata={
                                    'source': str(file_path),
                                    'sheet_name': sheet_name,
                                    'row_number': row_idx + 1,
                                    'file_type': 'excel',
                                    'file_name': file_path.name
                                }
                            )
                            documents.append(doc)
                
                return documents
            except ImportError:
                print("æœªå®‰è£…pandasåº“ï¼Œæ— æ³•è§£æExcelæ–‡ä»¶")
                return []
            except Exception:
                return []
        except Exception:
            return []
    
    def _load_html(self, file_path: Path) -> List[Document]:
        """åŠ è½½HTMLæ–‡ä»¶"""
        try:
            from langchain_community.document_loaders import UnstructuredHTMLLoader
            loader = UnstructuredHTMLLoader(str(file_path))
            documents = loader.load()
            
            # æ·»åŠ å…ƒæ•°æ®
            for doc in documents:
                doc.metadata.update({
                    'source': str(file_path),
                    'file_type': 'html',
                    'file_name': file_path.name
                })
            
            return documents
        except ImportError:
            print("æœªå®‰è£…unstructuredåº“ï¼Œå°è¯•ä½¿ç”¨BeautifulSoupè§£æHTML")
            try:
                from bs4 import BeautifulSoup
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                soup = BeautifulSoup(content, 'html.parser')
                
                # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
                for script in soup(["script", "style"]):
                    script.decompose()
                
                # æå–æ–‡æœ¬
                text = soup.get_text()
                # æ¸…ç†ç©ºç™½
                lines = (line.strip() for line in text.splitlines())
                chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
                text = '\n'.join(chunk for chunk in chunks if chunk)
                
                if text:
                    doc = Document(
                        page_content=text,
                        metadata={
                            'source': str(file_path),
                            'file_type': 'html',
                            'file_name': file_path.name,
                            'title': soup.title.string if soup.title else None
                        }
                    )
                    return [doc]
                return []
            except ImportError:
                print("æœªå®‰è£…BeautifulSoupåº“ï¼Œæ— æ³•è§£æHTMLæ–‡ä»¶")
                return []
            except Exception:
                return []
        except Exception:
            return []
    
    def _load_xml(self, file_path: Path) -> List[Document]:
        """åŠ è½½XMLæ–‡ä»¶"""
        try:
            from langchain_community.document_loaders import UnstructuredXMLLoader
            loader = UnstructuredXMLLoader(str(file_path))
            documents = loader.load()
            
            # æ·»åŠ å…ƒæ•°æ®
            for doc in documents:
                doc.metadata.update({
                    'source': str(file_path),
                    'file_type': 'xml',
                    'file_name': file_path.name
                })
            
            return documents
        except ImportError:
            print("æœªå®‰è£…unstructuredåº“ï¼Œå°è¯•ä½¿ç”¨xml.etreeè§£æXML")
            try:
                import xml.etree.ElementTree as ET
                
                tree = ET.parse(file_path)
                root = tree.getroot()
                
                def extract_text(element):
                    """é€’å½’æå–XMLå…ƒç´ çš„æ–‡æœ¬"""
                    texts = []
                    if element.text and element.text.strip():
                        texts.append(element.text.strip())
                    
                    for child in element:
                        child_texts = extract_text(child)
                        texts.extend(child_texts)
                        
                        if child.tail and child.tail.strip():
                            texts.append(child.tail.strip())
                    
                    return texts
                
                all_texts = extract_text(root)
                
                if all_texts:
                    text = '\n'.join(all_texts)
                    doc = Document(
                        page_content=text,
                        metadata={
                            'source': str(file_path),
                            'file_type': 'xml',
                            'file_name': file_path.name,
                            'root_tag': root.tag
                        }
                    )
                    return [doc]
                return []
            except Exception:
                return []
        except Exception:
            return []
    
    def _load_json(self, file_path: Path) -> List[Document]:
        """åŠ è½½JSONæ–‡æ¡£"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # å°†JSONå†…å®¹è½¬æ¢ä¸ºæ–‡æœ¬
            if isinstance(data, dict):
                content = json.dumps(data, ensure_ascii=False, indent=2)
            elif isinstance(data, list):
                content = json.dumps(data, ensure_ascii=False, indent=2)
            else:
                content = str(data)
            
            document = Document(
                page_content=content,
                metadata={
                    'source': str(file_path),
                    'file_type': 'json',
                    'file_name': file_path.name
                }
            )
            
            return [document]
            
        except Exception as e:
            print(f"åŠ è½½JSONæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return []
    
    def get_supported_formats(self) -> List[str]:
        """è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"""
        return list(self.supported_extensions.keys())
    
    def load_single_document(self, file_path: str) -> List[Document]:
        """åŠ è½½å•ä¸ªæ–‡æ¡£"""
        start_time = time.time()
        path_obj = Path(file_path)
        
        if not path_obj.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {path_obj}")
        
        file_extension = path_obj.suffix.lower()
        if file_extension not in self.supported_extensions:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_extension}")
        
        loader_func = self.supported_extensions[file_extension]
        documents = loader_func(path_obj)
        
        processing_time = time.time() - start_time
        
        # è®°å½•å•ä¸ªæ–‡æ¡£å¤„ç†å†å²
        if self.persistence_manager and documents:
            try:
                file_size = path_obj.stat().st_size if path_obj.exists() else 0
                self.persistence_manager.save_document_history(
                    file_path=str(path_obj),
                    file_name=path_obj.name,
                    file_size=file_size,
                    processing_time=processing_time,
                    success=True,
                    chunk_count=len(documents),
                    strategy=f"single-file-{self._get_file_type(file_extension)}"
                )
            except Exception as e:
                print(f"âš ï¸ æŒä¹…åŒ–è®°å½•å¤±è´¥: {e}")
        
        return documents
    
    def get_load_statistics(self) -> Dict:
        """è·å–æœ€è¿‘ä¸€æ¬¡åŠ è½½çš„ç»Ÿè®¡ä¿¡æ¯"""
        return getattr(self, 'load_stats', {})
    
    def get_supported_formats_info(self) -> Dict[str, List[str]]:
        """è·å–æ”¯æŒæ ¼å¼çš„è¯¦ç»†ä¿¡æ¯"""
        format_groups = {
            'Document Formats': ['.pdf', '.doc', '.docx', '.ppt', '.pptx'],
            'Text Formats': ['.txt', '.md', '.markdown', '.rst'],
            'Data Formats': ['.json', '.jsonl', '.csv', '.xlsx', '.xls'],
            'Web Formats': ['.html', '.htm', '.xml'],
            'Code Formats': ['.py', '.js', '.ts', '.java', '.cpp', '.c', '.cs', '.go', '.rs', '.php', '.rb', '.sh', '.sql'],
            'Config Formats': ['.yml', '.yaml', '.toml', '.ini', '.cfg', '.conf'],
            'Log Formats': ['.log']
        }
        
        # éªŒè¯æ”¯æŒçš„æ ¼å¼
        supported_formats = {}
        for category, extensions in format_groups.items():
            supported_formats[category] = [ext for ext in extensions if ext in self.supported_extensions]
        
        return supported_formats
